{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN7AqfbenKMdHVBR4BAIsXD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Mounting the sample images"],"metadata":{"id":"fWZEPNknqOGU"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","sample_img_dir = \"/content/drive/MyDrive/sample_img\"\n","image_files = [f for f in os.listdir(sample_img_dir) if f.endswith(('.jpg', '.JPG', '.png', '.PNG'))]\n","print(f\"Found {len(image_files)} images: {image_files}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hrESZh3B_LtP","executionInfo":{"status":"ok","timestamp":1742095781675,"user_tz":-330,"elapsed":29983,"user":{"displayName":"Pranav Kumar","userId":"16684040414897928961"}},"outputId":"9c3dae34-5d34-4bcc-ea74-7facc0265f8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Found 15 images: ['CarPlate.jpg', 'CarPlate12.jpg', 'CarPlate11.jpg', 'CarPlate2(JPG).jpg', 'CarPlate4.jpg', 'CarPlate15.jpg', 'CarPlate6.jpg', 'CarPlate7.jpg', 'CarPlate8.jpg', 'CarPlate9.jpg', 'CarPlate10.jpg', 'CarPlate5.jpg', 'CarPlate3.jpg', 'CarPlate13.jpg', 'CarPlate14.jpg']\n"]}]},{"cell_type":"markdown","source":["Since we defined our own class to check f1 score so we re defining it again to call back our custom object"],"metadata":{"id":"6AwjOVgwqTsh"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","class F1Score(tf.keras.metrics.Metric):\n","    def __init__(self, name=\"f1_score\", **kwargs):\n","        super(F1Score, self).__init__(name=name, **kwargs)\n","        self.true_positives = self.add_weight(name=\"tp\", initializer=\"zeros\")\n","        self.false_positives = self.add_weight(name=\"fp\", initializer=\"zeros\")\n","        self.false_negatives = self.add_weight(name=\"fn\", initializer=\"zeros\")\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        y_pred = tf.argmax(y_pred, axis=1)\n","        y_true = tf.cast(y_true, tf.int64)\n","\n","        tp = tf.reduce_sum(tf.cast(tf.equal(y_pred, y_true), tf.float32))\n","        fp = tf.reduce_sum(tf.cast(tf.not_equal(y_pred, y_true), tf.float32))\n","        fn = tf.reduce_sum(tf.cast(tf.not_equal(y_true, y_pred), tf.float32))\n","\n","        self.true_positives.assign_add(tp)\n","        self.false_positives.assign_add(fp)\n","        self.false_negatives.assign_add(fn)\n","\n","    def result(self):\n","        precision = self.true_positives / (self.true_positives + self.false_positives + tf.keras.backend.epsilon())\n","        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n","        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n","\n","    def reset_states(self):\n","        self.true_positives.assign(0)\n","        self.false_positives.assign(0)\n","        self.false_negatives.assign(0)\n","\n","\n","model_path = \"/content/drive/MyDrive/char_recog1.keras\"\n","model = tf.keras.models.load_model(\n","    model_path,\n","    custom_objects={'F1Score': F1Score}  #passing  the F1Score class as a custom object\n",")"],"metadata":{"id":"07lcHGTF_bAh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Integrating our cnn model with our character segmentationa and plate localiation code"],"metadata":{"id":"DKRG6RRxqpsI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YhTwDARk22Sw","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"15tnC8rfNhCUDOjAE9tqOZqmvixGr35rb"},"executionInfo":{"status":"ok","timestamp":1742095971112,"user_tz":-330,"elapsed":176952,"user":{"displayName":"Pranav Kumar","userId":"16684040414897928961"}},"outputId":"b31d16f0-1333-4b81-8227-a566862bc755"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import cv2 as cv\n","from skimage import measure\n","from skimage.measure import regionprops\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","\n","# Load the trained model\n","model_path = \"/content/drive/MyDrive/char_recog1.keras\"\n","model = tf.keras.models.load_model(model_path, custom_objects={'F1Score': F1Score})\n","\n","# Define index_to_char mapping\n","index_to_char = {i: str(i) if i < 10 else chr(ord('A') + i - 10) for i in range(36)}\n","\n","# Function to display the image\n","def ShowImage(img):\n","    plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n","    plt.show()\n","\n","# Function to resize the image for better display\n","def resize(img, scaleInPercent):\n","    width = int(img.shape[1] * scaleInPercent / 100)\n","    height = int(img.shape[0] * scaleInPercent / 100)\n","    dim = (width, height)\n","    return cv.resize(img, dim, interpolation=cv.INTER_AREA)\n","\n","# Dynamic parameter adjustment\n","def getAdaptiveParameters(img):\n","    height, width = img.shape[:2]\n","    return {\n","        'scale_factor': 1.05 if height > 1000 else 1.1,\n","        'min_neighbors': 5 if height > 1000 else 3,\n","        'block_size': max(11, int(width * 0.02)),\n","        'aspect_ratio_range': (1.8, 5.0),\n","        'area_threshold': max(300, (width * height) * 0.0005)\n","    }\n","\n","# Pre-processing function\n","def preProcessingImg(imgPath):\n","    imgGray = cv.imread(imgPath, cv.IMREAD_GRAYSCALE)\n","    clahe = cv.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n","    imgGray = clahe.apply(imgGray)\n","    imgAdaptiveThresh = cv.adaptiveThreshold(imgGray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 2)\n","    kernel = np.ones((3, 3), np.uint8)\n","    imgMorph = cv.morphologyEx(imgAdaptiveThresh, cv.MORPH_CLOSE, kernel)\n","    edges = cv.Canny(imgAdaptiveThresh, 30, 100)\n","    return imgGray, imgMorph, edges\n","\n","# Color classification for Indian plates\n","def isValidPlateColour(roi):\n","    hsv = cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n","    colour_profiles = {\n","        'private_white': ([0, 0, 150], [180, 30, 255]),\n","        'commercial_yellow': ([20, 100, 100], [30, 255, 255]),\n","        'government_blue': ([100, 50, 50], [130, 255, 255])\n","    }\n","    for _, (lower, upper) in colour_profiles.items():\n","        mask = cv.inRange(hsv, np.array(lower), np.array(upper))\n","        if np.sum(mask) > 0.3 * mask.size:\n","            return True\n","    return False\n","\n","# Function to check if a region is a potential license plate\n","def isPossibleLicensePlate(region, img, params):\n","    minRow, minCol, maxRow, maxCol = region.bbox\n","    region_height = maxRow - minRow\n","    region_width = maxCol - minCol\n","    aspect_ratio = region_width / region_height\n","    img_height, img_width = img.shape[:2]\n","    return (params['aspect_ratio_range'][0] <= aspect_ratio <= params['aspect_ratio_range'][1] and\n","            region.area > params['area_threshold'])\n","\n","# Haar cascade detection with dynamic parameters\n","def haarCascadeDetect(gray_img, params):\n","    cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_russian_plate_number.xml')\n","    return cascade.detectMultiScale(gray_img, scaleFactor=params['scale_factor'],\n","                                    minNeighbors=params['min_neighbors'], minSize=(30, 30))\n","\n","# Region properties detection\n","def regionPropsDetect(edges, img, params):\n","    labelImage = measure.label(edges)\n","    detectedRegions = []\n","    for region in regionprops(labelImage):\n","        if region.area < 50:\n","            continue\n","        if isPossibleLicensePlate(region, img, params):\n","            detectedRegions.append(region.bbox)\n","    return detectedRegions\n","\n","# Character segmentation function (integrated)\n","def segmentCharacters(plateImg):\n","    plateGray = cv.cvtColor(plateImg, cv.COLOR_BGR2GRAY)\n","    plateGray = cv.bilateralFilter(plateGray, 11, 17, 17)\n","    plateThresh = cv.adaptiveThreshold(plateGray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 21, 6)\n","    kernel_close = cv.getStructuringElement(cv.MORPH_ELLIPSE, (4, 4))\n","    kernel_open = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))\n","    plateThresh = cv.morphologyEx(plateThresh, cv.MORPH_CLOSE, kernel_close)\n","    plateThresh = cv.morphologyEx(plateThresh, cv.MORPH_OPEN, kernel_open)\n","    contours, _ = cv.findContours(plateThresh, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n","    plate_height, plate_width = plateGray.shape\n","    min_width = max(5, int(plate_width * 0.03))\n","    max_width = int(plate_width * 0.45)\n","    min_height = max(10, int(plate_height * 0.2))\n","    max_height = int(plate_height * 0.9)\n","    aspect_ratio_min = 0.15\n","    aspect_ratio_max = 1.5\n","    char_bboxes = []\n","    for contour in contours:\n","        x, y, w, h = cv.boundingRect(contour)\n","        aspect_ratio = w / float(h)\n","        if (w < min_width or w > max_width or\n","                h < min_height or h > max_height or\n","                aspect_ratio < aspect_ratio_min or\n","                aspect_ratio > aspect_ratio_max):\n","            continue\n","        char_bboxes.append((x, y, w, h))\n","    char_bboxes = merge_overlapping_boxes(char_bboxes)\n","    refined_boxes = []\n","    for box in char_bboxes:\n","        x, y, w, h = box\n","        avg_width = np.mean([b[2] for b in char_bboxes]) if char_bboxes else w\n","        if w > avg_width * 1.65:\n","            split_boxes = split_touching_characters(plateThresh[y:y + h, x:x + w], x, y)\n","            refined_boxes.extend(split_boxes)\n","        else:\n","            refined_boxes.append(box)\n","    refined_boxes = sorted(refined_boxes, key=lambda b: b[0])\n","    refined_boxes = filter_vertical_outliers(refined_boxes)\n","    return refined_boxes\n","\n","def merge_overlapping_boxes(bboxes, overlap_threshold=0.7):\n","    merged = []\n","    for box in sorted(bboxes, key=lambda b: b[0]):\n","        x, y, w, h = box\n","        found = False\n","        for i, mbox in enumerate(merged):\n","            mx, my, mw, mh = mbox\n","            dx = min(x + w, mx + mw) - max(x, mx)\n","            dy = min(y + h, my + mh) - max(y, my)\n","            if dx > 0 and dy > 0:\n","                overlap_area = dx * dy\n","                min_area = min(w * h, mw * mh)\n","                if overlap_area / min_area > overlap_threshold:\n","                    nx = min(x, mx)\n","                    ny = min(y, my)\n","                    nw = max(x + w, mx + mw) - nx\n","                    nh = max(y + h, my + mh) - ny\n","                    merged[i] = (nx, ny, nw, nh)\n","                    found = True\n","                    break\n","        if not found:\n","            merged.append(box)\n","    return merged\n","\n","def split_touching_characters(char_region, orig_x, orig_y):\n","    vertical_projection = np.sum(char_region, axis=0)\n","    threshold = 0.2 * np.max(vertical_projection)\n","    gaps = np.where(vertical_projection < threshold)[0]\n","    split_boxes = []\n","    if len(gaps) > 0:\n","        prev = 0\n","        for gap in gaps:\n","            if gap - prev > 2:\n","                split_boxes.append((orig_x + prev, orig_y, gap - prev, char_region.shape[0]))\n","                prev = gap\n","        split_boxes.append((orig_x + prev, orig_y, char_region.shape[1] - prev, char_region.shape[0]))\n","    else:\n","        split_boxes.append((orig_x, orig_y, char_region.shape[1], char_region.shape[0]))\n","    valid_boxes = []\n","    for box in split_boxes:\n","        x, y, w, h = box\n","        if w > 5 and h > 10:\n","            valid_boxes.append(box)\n","    return valid_boxes\n","\n","def filter_vertical_outliers(bboxes, threshold=0.7):\n","    if not bboxes:\n","        return []\n","    median_y = np.median([b[1] for b in bboxes])\n","    median_h = np.median([b[3] for b in bboxes])\n","    filtered = []\n","    for box in bboxes:\n","        y, h = box[1], box[3]\n","        if (abs(y - median_y) < median_h * 0.5 and\n","                abs(h - median_h) < median_h * threshold):\n","            filtered.append(box)\n","    return filtered\n","\n","# Function to preprocess character images for inference\n","def preprocess_char(char_img):\n","    # Convert to grayscale\n","    char_gray = cv.cvtColor(char_img, cv.COLOR_BGR2GRAY)\n","    # Apply binary thresholding (inverted: white characters on black background)\n","    _, char_thresh = cv.threshold(char_gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n","    # Resize to 28x28\n","    char_resized = cv.resize(char_thresh, (28, 28), interpolation=cv.INTER_AREA)\n","    # Convert to 3 channels (replicate grayscale to RGB)\n","    char_rgb = cv.cvtColor(char_resized, cv.COLOR_GRAY2RGB)\n","    # Normalize pixel values\n","    char_normalized = char_rgb.astype('float32') / 255.0\n","    return char_normalized\n","\n","# Function to recognize characters in a license plate\n","def recognize_characters(roi):\n","    char_bboxes = segmentCharacters(roi)  # Your existing segmentation function\n","    for idx, (cx, cy, cw, ch) in enumerate(char_bboxes):\n","        char_img = roi[cy:cy+ch, cx:cx+cw]\n","        if char_img.size == 0:\n","            continue\n","        # Preprocess the character image\n","        char_input = preprocess_char(char_img)\n","        char_input = np.expand_dims(char_input, axis=0)\n","        # Predict the character\n","        predictions = model.predict(char_input, verbose=0)\n","        predicted_idx = np.argmax(predictions, axis=1)[0]\n","        predicted_char = index_to_char.get(predicted_idx, '?')\n","        print(f\"  Character {idx + 1}: {predicted_char}\")\n","        # Annotate prediction on the image\n","        cv.putText(roi, predicted_char, (cx, cy-5), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n","\n","# License plate localization function with character segmentation\n","def plateLocalization(imgPath):\n","    img = cv.imread(imgPath)\n","    params = getAdaptiveParameters(img)\n","    gray, thresh, edges = preProcessingImg(imgPath)\n","    detected_plates = []\n","\n","    # Haar Cascade Detection\n","    plates_haar = haarCascadeDetect(gray, params)\n","    for (x, y, w, h) in plates_haar:\n","        roi = img[y:y + h, x:x + w]\n","        if isValidPlateColour(roi):\n","            detected_plates.append((x, y, w, h))\n","            cv.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 3)\n","            # Recognize characters in the detected plate\n","            recognize_characters(roi)\n","\n","    # Regionprops Detection\n","    regions = regionPropsDetect(edges, img, params)\n","    for bbox in regions:\n","        minCol, minRow, maxCol, maxRow = bbox\n","        roi = img[minRow:maxRow, minCol:maxCol]\n","        if isValidPlateColour(roi):\n","            detected_plates.append(bbox)\n","            cv.rectangle(img, (minCol, minRow), (maxCol, maxRow), (0, 0, 255), 2)\n","            # Recognize characters in the detected plate\n","            recognize_characters(roi)\n","\n","    # Display results\n","    ShowImage(resize(img, 60))\n","\n","# Process all images in the sample directory\n","sample_img_dir = \"/content/drive/MyDrive/sample_img\"\n","image_files = [f for f in os.listdir(sample_img_dir) if f.endswith(('.jpg', '.JPG', '.png', '.PNG'))]\n","print(f\"Found {len(image_files)} images: {image_files}\")\n","\n","for img_file in image_files:\n","    img_path = os.path.join(sample_img_dir, img_file)\n","    print(f\"Processing {img_file}...\")\n","    plateLocalization(img_path)"]}]}